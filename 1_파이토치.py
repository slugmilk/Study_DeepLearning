# -*- coding: utf-8 -*-
"""1. 파이토치.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wFeG91pirciPca2jVfmg-ZHXg5LEWWir

# **1. 파이토치(Pytorch)**
* 텐서플로우와 함께 머신러닝, 딥러닝에서 가장 널리 사용되는 프레임워크
* 초기에는 Torch라는 이름으로 Lua언어 기반으로 만들어졌으나, 파이썬 기반으로 변경한 것이 파이토치
* 뉴욕대학교와 페이스북(메가)이 공동으로 개발하였고, 현재 가장 대중적이고 사용자가 많은 머신러닝, 딥러닝 프레임워크
"""

import torch
print(torch.__version__)

"""### 1-1. 스칼라(Scalar)
* 하나의 상수를 의미
"""

var1 = torch.tensor([10]) # 스칼라
var1

type(var1) # 텐서형

var2 = torch.tensor([10.5]) # 다양한 자료형 사용 가능
var2

# 두 스칼라의 사칙 연산
print(var1 + var2)
print(var1 - var2)
print(var1 * var2)
print(var1 / var2)

"""### 1-2. 벡터(Vector)
* 상수가 두 개 이상 나열된 경우
"""

vec1 = torch.tensor([1, 2, 3])
vec1

vec2 = torch.tensor([1.4, 2.5, 3.3])
vec2

# 두 벡터의 사칙 연산 (같은 포지션끼리 계산됨)
print(vec1 + vec2)
print(vec1 - vec2)
print(vec1 * vec2)
print(vec1 / vec2)

vec3 = torch.tensor([5, 10])
vec3

# vec1 + vec3
# RuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0

"""### 1-3. 행렬(Matrix)
* 2개 이상의 벡터값을 가지고 만들어진 값으로, 행과 열의 개념을 가진 데이터들의 나열
"""

mat1 = torch.tensor([[1, 2], [3, 4]])
mat1

mat2 = torch.tensor([[7, 8], [9, 10]])
mat2

# 두 행렬의 사칙연산
print(mat1 + mat2)
print(mat1 - mat2)
print(mat1 * mat2)
print(mat1 / mat2)

"""### 1-4. 텐서(Tensor)
* 다수의 행렬이 모이면 텐서
* 배열이나 행렬과 매우 유사한 특수 자료구조
* 파이토치는 텐서를 사용하여 모델의 입력과 출력, 모델의 매개변수들을 처리

 <center><img src='https://miro.medium.com/max/875/1*jRyyMAhS_NZxqyv3EoLCvg.png' width=500></center>
"""

tensor1 = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])
tensor1

tensor2 = torch.tensor([[[9, 10], [11, 12]], [[13, 14], [15, 16]]])
tensor2

# 두 텐서의 사칙 연산
print(tensor1 + tensor1)
print(tensor1 - tensor1)
print(tensor1 * tensor1)
print(tensor1 / tensor1)

# 함수를 이용한 사칙 연산
print(torch.add(tensor1, tensor2))
print(torch.subtract(tensor1, tensor2))
print(torch.multiply(tensor1, tensor2))
print(torch.divide(tensor1, tensor2))
print(torch.matmul(tensor1, tensor2)) # 행렬곱

print(tensor1.add_(tensor2)) # tensor1에 결과를 다시 저장
print(tensor1.subtract_(tensor2))

"""# **2. 파이토치와 텐서**"""

data = [[1, 2], [3, 4]]
data

data_tensor = torch.tensor(data)
data_tensor

import numpy as np

ndarray = np.array(data_tensor)
ndarray

data_tensor = torch.tensor(ndarray)
data_tensor

a = torch.ones(2, 3) # 요소가 모두 1인 2행 3열짜리 행렬 만듦
a

b = torch.zeros(3, 4) # 요소가 모두 0인 3행 4열짜리 행렬 만듦
b

c = torch.full((3, 4), 7) # 요소가 모두 7인 3*4 행렬
c

d = torch.empty(2, 3) # 2*3 행렬에 의미없는 값
d

e = torch.eye(5) # 5*5 단위행렬
print(e)

f = torch.arange(10) # 0부터 9
f

g = torch.rand(2, 3) # 2*3 랜덤값
g

h = torch.randn(2, 3) # 평균이 0이고, 표준편차가 1인 정규분포에서 무작위 샘플링
h

i = torch.arange(16).reshape(2, 2, 4) # 2행 4열짜리 2개 (a, b, c -> b행 c열짜리 a개)
i, i.shape

# permute(): 차원을 지정한 인덱스로 변환
# i.shape = ([2, 2, 4])
j = i.permute((2, 1, 0)) # [2, 2, 4] -> [4, 2, 2]
j, j.shape

a = torch.arange(1, 13).reshape(3, 4)
a

a[1]

a[0, -1]

a[1:-1]

a[:2, 2:]

"""# **3. 코랩에서 GPU 사용하기**
* 코랩에서 device 변경하는 방법
  * 상단 메뉴 -> 런타임 -> 런타임 유형변경 -> 하드웨어 가속기를 GPU호 변경 -> 저장 -> 세션 다시 시작 및 모두 실행
"""

tensor = torch.rand(3, 4)
print(tensor)
print(f'shape: {tensor.shape}')
print(f'type: {type(tensor)}')
print(f'dtype: {tensor.dtype}')
print(f'device: {tensor.device}')

# is_available(): gpu를 사용할 수 있는지 여부
if torch.cuda.is_available():
  print('GPU를 사용할 수 있음')
  tensor = tensor.to('cuda')
print(f'device: {tensor.device}')

